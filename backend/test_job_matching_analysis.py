#!/usr/bin/env python3
"""
ì§ë¬´ ë§¤ì¹­ ì •í™•ë„ ì‹¬ì¸µ ë¶„ì„ í…ŒìŠ¤íŠ¸

ë¬¸ì œ: ê²€ìƒ‰ ê²°ê³¼ì— ê´€ë ¨ ì—†ëŠ” ê³µê³ ê°€ í¬í•¨ë˜ëŠ” í˜„ìƒ
ëª©í‘œ: ì›ì¸ íŒŒì•… ë° ê°œì„  ë°©í–¥ ë„ì¶œ
"""

import asyncio
import httpx
import json
from typing import Optional, Dict, List
from collections import Counter, defaultdict
from datetime import datetime

API_BASE = "http://localhost:8000"

LOCATIONS = {
    "ê°•ë‚¨ì—­": {"latitude": 37.497916, "longitude": 127.027632, "address": "ê°•ë‚¨ì—­"},
}

# ë¶„ì„ ëŒ€ìƒ ì§ë¬´
ANALYSIS_JOBS = [
    {
        "name": "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
        "exact_keywords": ["í”„ë¡ íŠ¸ì—”ë“œ", "frontend", "í”„ë¡ íŠ¸", "front-end"],
        "related_keywords": ["react", "vue", "angular", "javascript", "ì›¹ê°œë°œ", "ì›¹í¼ë¸”ë¦¬ì…”"],
        "unrelated_keywords": ["ë°±ì—”ë“œ", "backend", "ì„œë²„", "java", "python", "ë§ˆì¼€íŒ…", "ë””ìì¸", "ì˜ì—…"]
    },
    {
        "name": "ë°±ì—”ë“œ ê°œë°œì",
        "exact_keywords": ["ë°±ì—”ë“œ", "backend", "ì„œë²„ê°œë°œ", "server"],
        "related_keywords": ["java", "python", "node", "spring", "django", "api"],
        "unrelated_keywords": ["í”„ë¡ íŠ¸ì—”ë“œ", "frontend", "react", "vue", "ë§ˆì¼€íŒ…", "ë””ìì¸"]
    },
    {
        "name": "UI/UX ë””ìì´ë„ˆ",
        "exact_keywords": ["ui", "ux", "ui/ux", "uiux"],
        "related_keywords": ["ì‚¬ìš©ìê²½í—˜", "ì¸í„°í˜ì´ìŠ¤", "í”„ë¡œë•íŠ¸ë””ìì¸", "figma"],
        "unrelated_keywords": ["ê·¸ë˜í”½", "ì˜ìƒ", "3d", "ë§ˆì¼€íŒ…", "ê°œë°œ", "ë°±ì—”ë“œ"]
    },
    {
        "name": "ë°ì´í„° ë¶„ì„ê°€",
        "exact_keywords": ["ë°ì´í„°ë¶„ì„", "data analyst", "ë¶„ì„ê°€"],
        "related_keywords": ["bi", "sql", "tableau", "í†µê³„", "ì• ë„ë¦¬ìŠ¤íŠ¸"],
        "unrelated_keywords": ["ë°ì´í„°ì—”ì§€ë‹ˆì–´", "ë¨¸ì‹ ëŸ¬ë‹", "ê°œë°œ", "ë§ˆì¼€íŒ…"]
    },
    {
        "name": "í¼í¬ë¨¼ìŠ¤ ë§ˆì¼€í„°",
        "exact_keywords": ["í¼í¬ë¨¼ìŠ¤", "performance", "í¼í¬ë¨¼ìŠ¤ë§ˆì¼€í„°"],
        "related_keywords": ["ê´‘ê³ ", "cpc", "cpa", "í˜ì´ìŠ¤ë¶", "êµ¬ê¸€ì• ì¦ˆ"],
        "unrelated_keywords": ["ì½˜í…ì¸ ", "ë¸Œëœë“œ", "pr", "ê°œë°œ", "ë””ìì¸"]
    },
]


class JobMatchingAnalyzer:
    def __init__(self):
        self.client: Optional[httpx.AsyncClient] = None

    async def setup(self):
        self.client = httpx.AsyncClient(timeout=60.0)

    async def teardown(self):
        if self.client:
            await self.client.aclose()

    async def chat(self, message: str) -> Dict:
        payload = {
            "message": message,
            "user_location": LOCATIONS["ê°•ë‚¨ì—­"]
        }
        response = await self.client.post(f"{API_BASE}/chat", json=payload)
        return response.json()

    def analyze_title_match(self, title: str, job_config: Dict) -> Dict:
        """íƒ€ì´í‹€ ë§¤ì¹­ ë¶„ì„"""
        title_lower = title.lower()

        exact_match = any(kw.lower() in title_lower for kw in job_config["exact_keywords"])
        related_match = any(kw.lower() in title_lower for kw in job_config["related_keywords"])
        unrelated_match = any(kw.lower() in title_lower for kw in job_config["unrelated_keywords"])

        if exact_match:
            category = "ì •í™•ë§¤ì¹­"
        elif related_match:
            category = "ìœ ì‚¬ë§¤ì¹­"
        elif unrelated_match:
            category = "ë¬´ê´€ê³µê³ "
        else:
            category = "ë¶„ë¥˜ë¶ˆê°€"

        return {
            "category": category,
            "exact": exact_match,
            "related": related_match,
            "unrelated": unrelated_match,
        }

    async def analyze_job(self, job_config: Dict) -> Dict:
        """ë‹¨ì¼ ì§ë¬´ ë¶„ì„"""
        job_name = job_config["name"]
        query = f"ê°•ë‚¨ì—ì„œ ì—°ë´‰ ë¬´ê´€ {job_name}"

        print(f"\n{'='*70}")
        print(f"ë¶„ì„ ëŒ€ìƒ: {job_name}")
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        print("="*70)

        resp = await self.chat(query)
        jobs = resp.get("jobs", [])
        params = resp.get("search_params", {})
        search_keywords = params.get("job_keywords", [])

        print(f"\n[ê²€ìƒ‰ íŒŒë¼ë¯¸í„°]")
        print(f"  - AIê°€ ìƒì„±í•œ job_keywords: {search_keywords}")

        if not jobs:
            print(f"\nê²°ê³¼ ì—†ìŒ")
            return {"job_name": job_name, "total": 0, "categories": {}}

        # ê²°ê³¼ ë¶„ì„
        categories = defaultdict(list)
        title_words = Counter()

        print(f"\n[ê²°ê³¼ ë¶„ì„] ì´ {len(jobs)}ê±´")
        print("-"*70)

        for i, job in enumerate(jobs[:20]):  # ìƒìœ„ 20ê°œ ë¶„ì„
            title = job.get("title", "")
            company = job.get("company_name", "")
            job_keywords = job.get("job_keywords", [])

            analysis = self.analyze_title_match(title, job_config)
            categories[analysis["category"]].append({
                "title": title,
                "company": company,
            })

            # íƒ€ì´í‹€ ë‹¨ì–´ ìˆ˜ì§‘
            for word in title.split():
                if len(word) > 1:
                    title_words[word] += 1

            # ìƒì„¸ ì¶œë ¥
            status = {
                "ì •í™•ë§¤ì¹­": "âœ…",
                "ìœ ì‚¬ë§¤ì¹­": "ğŸ”¶",
                "ë¬´ê´€ê³µê³ ": "âŒ",
                "ë¶„ë¥˜ë¶ˆê°€": "â“"
            }[analysis["category"]]

            print(f"  {status} [{analysis['category']}] {title[:50]}")

        # ìš”ì•½
        print(f"\n[ë¶„ë¥˜ ìš”ì•½]")
        total = len(jobs[:20])
        for cat in ["ì •í™•ë§¤ì¹­", "ìœ ì‚¬ë§¤ì¹­", "ë¬´ê´€ê³µê³ ", "ë¶„ë¥˜ë¶ˆê°€"]:
            count = len(categories[cat])
            rate = count / total * 100 if total > 0 else 0
            print(f"  - {cat}: {count}ê±´ ({rate:.0f}%)")

        # íƒ€ì´í‹€ì— ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´
        print(f"\n[íƒ€ì´í‹€ ë¹ˆì¶œ ë‹¨ì–´ Top 10]")
        for word, count in title_words.most_common(10):
            print(f"  - {word}: {count}íšŒ")

        # ë¬¸ì œ ê³µê³  ìƒì„¸ ë¶„ì„
        if categories["ë¬´ê´€ê³µê³ "] or categories["ë¶„ë¥˜ë¶ˆê°€"]:
            print(f"\n[ë¬¸ì œ ê³µê³  ìƒì„¸ ë¶„ì„]")
            problem_jobs = categories["ë¬´ê´€ê³µê³ "] + categories["ë¶„ë¥˜ë¶ˆê°€"]
            for pj in problem_jobs[:5]:
                print(f"  âŒ {pj['company']} - {pj['title']}")

        return {
            "job_name": job_name,
            "search_keywords": search_keywords,
            "total": len(jobs),
            "analyzed": min(len(jobs), 20),
            "categories": {k: len(v) for k, v in categories.items()},
            "accuracy": len(categories["ì •í™•ë§¤ì¹­"]) / min(len(jobs), 20) * 100 if jobs else 0,
            "relevance": (len(categories["ì •í™•ë§¤ì¹­"]) + len(categories["ìœ ì‚¬ë§¤ì¹­"])) / min(len(jobs), 20) * 100 if jobs else 0,
        }

    async def analyze_keyword_generation(self):
        """AI í‚¤ì›Œë“œ ìƒì„± íŒ¨í„´ ë¶„ì„"""
        print("\n" + "="*70)
        print("AI í‚¤ì›Œë“œ ìƒì„± íŒ¨í„´ ë¶„ì„")
        print("="*70)

        test_queries = [
            "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
            "í”„ë¡ íŠ¸ì—”ë“œ",
            "FE ê°œë°œì",
            "React ê°œë°œì",
            "ì›¹ í”„ë¡ íŠ¸ì—”ë“œ",
            "ë°±ì—”ë“œ ê°œë°œì",
            "ì„œë²„ ê°œë°œì",
            "Java ê°œë°œì",
            "UI/UX ë””ìì´ë„ˆ",
            "UX ë””ìì´ë„ˆ",
            "í”„ë¡œë•íŠ¸ ë””ìì´ë„ˆ",
        ]

        print("\n[ì¿¼ë¦¬ë³„ ìƒì„± í‚¤ì›Œë“œ]")
        for query in test_queries:
            full_query = f"ê°•ë‚¨ì—ì„œ ì—°ë´‰ ë¬´ê´€ {query}"
            resp = await self.chat(full_query)
            params = resp.get("search_params", {})
            keywords = params.get("job_keywords", [])

            print(f"\n  '{query}'")
            print(f"    â†’ {keywords}")

    async def analyze_db_matching_logic(self):
        """DB ë§¤ì¹­ ë¡œì§ ë¶„ì„ - ë™ì¼ í‚¤ì›Œë“œë¡œ ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€"""
        print("\n" + "="*70)
        print("DB ë§¤ì¹­ ë¡œì§ ë¶„ì„")
        print("="*70)

        # ê°™ì€ ì˜ë¯¸, ë‹¤ë¥¸ í‘œí˜„
        equivalent_queries = [
            ("í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì", "í”„ë¡ íŠ¸ì—”ë“œ"),
            ("í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì", "Frontend Developer"),
            ("ë°±ì—”ë“œ ê°œë°œì", "ì„œë²„ ê°œë°œì"),
            ("UI/UX ë””ìì´ë„ˆ", "UX ë””ìì´ë„ˆ"),
        ]

        for query1, query2 in equivalent_queries:
            resp1 = await self.chat(f"ê°•ë‚¨ì—ì„œ ì—°ë´‰ ë¬´ê´€ {query1}")
            resp2 = await self.chat(f"ê°•ë‚¨ì—ì„œ ì—°ë´‰ ë¬´ê´€ {query2}")

            jobs1 = set(j.get("id") for j in resp1.get("jobs", []))
            jobs2 = set(j.get("id") for j in resp2.get("jobs", []))

            overlap = len(jobs1 & jobs2)
            total = len(jobs1 | jobs2)
            overlap_rate = overlap / total * 100 if total > 0 else 0

            print(f"\n  '{query1}' vs '{query2}'")
            print(f"    - ê²°ê³¼1: {len(jobs1)}ê±´, ê²°ê³¼2: {len(jobs2)}ê±´")
            print(f"    - ì¤‘ë³µ: {overlap}ê±´, ì¤‘ë³µë¥ : {overlap_rate:.0f}%")

    async def analyze_job_keywords_field(self):
        """DBì˜ job_keywords í•„ë“œ ë¶„ì„"""
        print("\n" + "="*70)
        print("DB job_keywords í•„ë“œ ë¶„ì„")
        print("="*70)

        resp = await self.chat("ê°•ë‚¨ì—ì„œ ì—°ë´‰ ë¬´ê´€ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì")
        jobs = resp.get("jobs", [])

        print(f"\n[ìƒ˜í”Œ ê³µê³ ì˜ job_keywords í•„ë“œ]")
        for job in jobs[:10]:
            title = job.get("title", "")
            job_keywords = job.get("job_keywords", [])
            print(f"\n  ì œëª©: {title}")
            print(f"  keywords: {job_keywords[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ

    async def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        await self.setup()

        print("\n" + "#"*70)
        print("# ì§ë¬´ ë§¤ì¹­ ì •í™•ë„ ì‹¬ì¸µ ë¶„ì„")
        print("#"*70)
        print(f"ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # 1. ê° ì§ë¬´ë³„ ìƒì„¸ ë¶„ì„
        all_results = []
        for job_config in ANALYSIS_JOBS:
            result = await self.analyze_job(job_config)
            all_results.append(result)
            await asyncio.sleep(0.5)

        # 2. AI í‚¤ì›Œë“œ ìƒì„± íŒ¨í„´ ë¶„ì„
        await self.analyze_keyword_generation()

        # 3. ë™ì˜ì–´ ì¿¼ë¦¬ ê²°ê³¼ ë¹„êµ
        await self.analyze_db_matching_logic()

        # 4. job_keywords í•„ë“œ ë¶„ì„
        await self.analyze_job_keywords_field()

        # ìµœì¢… ìš”ì•½
        print("\n" + "="*70)
        print("ìµœì¢… ë¶„ì„ ìš”ì•½")
        print("="*70)

        print("\n[ì§ë¬´ë³„ ì •í™•ë„]")
        print("-"*50)
        print(f"{'ì§ë¬´':<20} {'ì •í™•ë§¤ì¹­':<10} {'ê´€ë ¨ì„±':<10} {'ì´ê±´ìˆ˜':<10}")
        print("-"*50)

        for r in all_results:
            print(f"{r['job_name']:<20} {r['accuracy']:.0f}%{'':<6} {r['relevance']:.0f}%{'':<6} {r['total']}ê±´")

        avg_accuracy = sum(r['accuracy'] for r in all_results) / len(all_results)
        avg_relevance = sum(r['relevance'] for r in all_results) / len(all_results)

        print("-"*50)
        print(f"{'í‰ê· ':<20} {avg_accuracy:.0f}%{'':<6} {avg_relevance:.0f}%")

        # ë¬¸ì œ ì›ì¸ ë¶„ì„
        print("\n" + "="*70)
        print("ë¬¸ì œ ì›ì¸ ë¶„ì„")
        print("="*70)

        print("""
[ê°€ì„¤ 1] AIê°€ ë„ˆë¬´ í¬ê´„ì ì¸ í‚¤ì›Œë“œë¥¼ ìƒì„±
  - "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì" â†’ ["í”„ë¡ íŠ¸ì—”ë“œ", "ê°œë°œì", "React", "Vue", ...]
  - "ê°œë°œì" í‚¤ì›Œë“œê°€ ë°±ì—”ë“œ, í’€ìŠ¤íƒ ë“± ëª¨ë“  ê°œë°œ ê³µê³ ë¥¼ ë§¤ì¹­

[ê°€ì„¤ 2] DBì˜ job_keywords í•„ë“œê°€ ë„ˆë¬´ ê´‘ë²”ìœ„
  - í•˜ë‚˜ì˜ ê³µê³ ì— ë§ì€ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì–´ ê³¼ë§¤ì¹­ ë°œìƒ
  - ì˜ˆ: í”„ë¡ íŠ¸ì—”ë“œ ê³µê³ ì— "ê°œë°œì", "IT", "ì†Œí”„íŠ¸ì›¨ì–´" ë“± ì¼ë°˜ í‚¤ì›Œë“œ í¬í•¨

[ê°€ì„¤ 3] ë§¤ì¹­ ë¡œì§ì´ OR ì¡°ê±´ìœ¼ë¡œ ë™ì‘
  - job_keywords ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ ê²°ê³¼ì— í¬í•¨
  - AND ì¡°ê±´ì´ë‚˜ ê°€ì¤‘ì¹˜ ì ìš© í•„ìš”

[ê°€ì„¤ 4] íƒ€ì´í‹€ ìš°ì„  ì •ë ¬ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŒ
  - íƒ€ì´í‹€ì— ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ê³µê³ ê°€ ìƒìœ„ì— ì˜¤ì§€ ì•ŠìŒ
""")

        await self.teardown()

        return all_results


async def main():
    analyzer = JobMatchingAnalyzer()
    results = await analyzer.run_full_analysis()

    # ê²°ê³¼ ì €ì¥
    with open("job_matching_analysis.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nê²°ê³¼ê°€ job_matching_analysis.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
